# -*- coding: utf-8 -*-
"""Power_Consumption _prediction_model_usingLSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16_XtjcynjJbKIQW-2Cfu5uobb4GkV0FY
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pprint
# %matplotlib inline

df = pd.read_csv("/content/AEP_hourly (1).csv")
print("="*50)
print("First Five Rows ","\n")
print(df.head(2),"\n")

print("="*50)
print("Information About Dataset","\n")
print(df.info(),"\n")

print("="*50)
print("Describe the Dataset ","\n")
print(df.describe(),"\n")

print("="*50)
print("Null Values t ","\n")
print(df.isnull().sum(),"\n")

# Extract all Data Like Year MOnth Day Time etc
# dataset = df.copy()
# dataset["Datetime"] = pd.to_datetime(dataset["Datetime"])
# dataset["Month"] = pd.to_datetime(df["Datetime"]).dt.month
# dataset["Year"] = pd.to_datetime(df["Datetime"]).dt.year
# dataset["Date"] = pd.to_datetime(df["Datetime"]).dt.date
# dataset["Time"] = pd.to_datetime(df["Datetime"]).dt.time
# # dataset["Week"] = pd.to_datetime(df["Datetime"]).dt.week
# dataset["Week"] = dataset["Datetime"].dt.isocalendar().week
# dataset["Day"] = pd.to_datetime(df["Datetime"]).dt.day_name()
# dataset = df.set_index("Datetime")
# dataset.index = pd.to_datetime(dataset.index)
# dataset.head(1)
dataset = df.copy()
dataset["Datetime"] = pd.to_datetime(dataset["Datetime"])

# Extracting various components
dataset["Month"] = dataset["Datetime"].dt.month
dataset["Year"] = dataset["Datetime"].dt.year
dataset["Date"] = dataset["Datetime"].dt.date
dataset["Time"] = dataset["Datetime"].dt.time
dataset["Week"] = dataset["Datetime"].dt.isocalendar().week
dataset["Day"] = dataset["Datetime"].dt.day_name()

# Set the Datetime column as the index
dataset.set_index("Datetime", inplace=True)

# Display the modified dataset
print(dataset.head(1))

dataset.head()

# How many Unique Year do we Have in Datase
print(dataset.Year.unique(),"\n")
print("Total Number of Unique Year", dataset.Year.nunique(), "\n")

from matplotlib import style

fig = plt.figure()
ax1 = plt.subplot2grid((1,1), (0,0))
##ggplot is used unique set of colour palletes and easy visualization
style.use('ggplot')
#lineplot is used to to know energy consuption year by year
sns.lineplot(x=dataset["Year"], y=dataset["AEP_MW"], data=df)
sns.set(rc={'figure.figsize':(15,6)})

plt.title("Energy consumptionnin Year 2004")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True)
plt.legend()

for label in ax1.xaxis.get_ticklabels():
    label.set_rotation(90)


plt.title("Energy Consumption According to Year")

# Filter dataset by year and extract necessary columns
year_2004 = dataset[dataset["Year"] == 2004]
y_2004 = year_2004["AEP_MW"].to_list()
x_2004 = year_2004["Date"].to_list()
ax1.plot(x_2004,y_2004, color="green", linewidth=1.7)

from matplotlib import style


fig = plt.figure()

ax1= fig.add_subplot(311)
ax2= fig.add_subplot(312)
ax3= fig.add_subplot(313)


style.use('ggplot')

# y_2004 = dataset["2004"]["AEP_MW"].to_list()
# x_2004 = dataset["2004"]["Date"].to_list()
year_2004 = dataset[dataset["Year"] == 2004]
y_2004 = year_2004["AEP_MW"].to_list()
x_2004 = year_2004["Date"].to_list()
ax1.plot(x_2004,y_2004, color="green", linewidth=1.7)


# y_2005 = dataset["2005"]["AEP_MW"].to_list()
# x_2005 = dataset["2005"]["Date"].to_list()
year_2005 = dataset[dataset["Year"] == 2005]
y_2005 = year_2005["AEP_MW"].to_list()
x_2005 = year_2005["Date"].to_list()
ax2.plot(x_2005, y_2005, color="green", linewidth=1)


# y_2006 = dataset["2006"]["AEP_MW"].to_list()
# x_2006 = dataset["2006"]["Date"].to_list()
year_2006 = dataset[dataset["Year"] == 2005]
y_2006 = year_2006["AEP_MW"].to_list()
x_2006 = year_2006["Date"].to_list()
ax3.plot(x_2006, y_2006, color="green", linewidth=1)


plt.rcParams["figure.figsize"] = (18,8)
plt.title("Energy consumptionnin")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True, alpha=1)
plt.legend()

for label in ax1.xaxis.get_ticklabels():
    label.set_rotation(90)

sns.distplot(dataset["AEP_MW"])
plt.title("Ennergy Distribution")

# NewDataSet = dataset.resample('D').mean()
# Select only numeric columns for resampling
numeric_columns = dataset.select_dtypes(include=['float64', 'int64'])

# Resample numeric columns
NewDataSet = numeric_columns.resample('D').mean()

#resample to change freequency of time series , D specifies new freequency daily , mean function nean value for each day aggregates hourly data to daily data

print(NewDataSet.head(5))

print("Old Dataset ",dataset.shape )
print("New  Dataset ",NewDataSet.shape )

TestData = NewDataSet.tail(100)
#creates New Data frame with row values for each day will be mean of the hourly data
Training_Set = NewDataSet.iloc[:,0:1]

Training_Set = Training_Set[:-60]

print("Training Set Shape ", Training_Set.shape)
print("Test Set Shape ", TestData.shape)

from sklearn.preprocessing import MinMaxScaler
Training_Set = Training_Set
sc = MinMaxScaler(feature_range=(0, 1))
Train = sc.fit_transform(Training_Set)

X_Train = []
Y_Train = []

# Range should be fromm 60 Values to END
for i in range(60, Train.shape[0]):

    # X_Train 0-59
    X_Train.append(Train[i-60:i])

    # Y Would be 60 th Value based on past 60 Values
    Y_Train.append(Train[i])

# Convert into Numpy Array
X_Train = np.array(X_Train)
Y_Train = np.array(Y_Train)

print(X_Train.shape)
print(Y_Train.shape)

# Shape should be Number of [Datapoints , Steps , 1 )
# we convert into 3-d Vector or #rd Dimesnsion
X_Train = np.reshape(X_Train, newshape=(X_Train.shape[0], X_Train.shape[1], 1))
X_Train.shape

print(X_Train.shape[1])

from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dropout
from tensorflow.keras.layers import Dense
regressor = Sequential()

# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_Train.shape[1], 1)))
regressor.add(Dropout(0.2))

# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))

# Adding the output layer
regressor.add(Dense(units = 1))

# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics="accuracy")

print(regressor.summary())

regressor.fit(X_Train, Y_Train, epochs = 50, batch_size = 32)

TestData.head(2)

TestData.shape

NewDataSet.shape

Df_Total = pd.concat((NewDataSet[["AEP_MW"]], TestData[["AEP_MW"]]), axis=0)

Df_Total.shape

inputs = Df_Total[len(Df_Total) - len(TestData) - 60:].values
inputs.shape

inputs = Df_Total[len(Df_Total) - len(TestData) - 60:].values

# We need to Reshape
inputs = inputs.reshape(-1,1)

# Normalize the Dataset
inputs = sc.transform(inputs)

X_test = []
for i in range(60, 160):
    X_test.append(inputs[i-60:i])

# Convert into Numpy Array
X_test = np.array(X_test)

# Reshape before Passing to Network
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Pass to Model
predicted_stock_price = regressor.predict(X_test)

# Do inverse Transformation to get Values
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt  = predicted_stock_price
dates = TestData.index.to_list()

Machine_Df = pd.DataFrame(data={
    "Date":dates,
    "TrueMegaWatt": True_MegaWatt,
    "PredictedMeagWatt":[x[0] for x in Predicted_MegaWatt ]
})

Machine_Df

True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt  = [x[0] for x in Predicted_MegaWatt ]
dates = TestData.index.to_list()

fig = plt.figure()

ax1= fig.add_subplot(111)

x = dates
y = True_MegaWatt

y1 = Predicted_MegaWatt

plt.plot(x,y, color="green")
plt.plot(x,y1, color="red")
# beautify the x-labels
plt.gcf().autofmt_xdate()
plt.xlabel('Dates')
plt.ylabel("Power in MW")
plt.title("Machine Learned the Pattern Predicting Future Values ")
plt.legend()

from sklearn.metrics import r2_score

r2_score_value = r2_score(True_MegaWatt, Predicted_MegaWatt)
print("R2 Score:", r2_score_value)